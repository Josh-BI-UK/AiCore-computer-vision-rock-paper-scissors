{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 3> AiCore Project </font><br> \n",
    "<font size = 2> Python coding project by: [Joshua Payne](https://github.com/Josh-BI-UK) </font>\n",
    "\n",
    "# Computer Vision Rock Paper Scissors (RPC) - Milestone 2\n",
    "The class is already prepared. Now the game starts\n",
    "<br> ---<br>\n",
    "<font size=1><b>\n",
    "Denotes:<br><i>\n",
    "[✔︎] = completed task.<br> \n",
    "[ ] = uncompleted task.\n",
    "</b></i></font>\n",
    "<br> ---<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to Teachable-Machine  to start creating the model. Each class is trained with images of yourself showing each option to the camera. The \"Nothing\" class represents the lack of option in the image. Remember that the more images you train with, the more accurate the model will be\n",
    "\n",
    "Milestone 1: Set-up the environment\n",
    "Milestone 2: Create the computer vision system:\n",
    "\n",
    "The first task consists of creating a computer vision system - also known as a model - that detects whether the user is showing Rock, Paper, or Scissors to the camera.\n",
    "\n",
    "Task 1: Create an image project model with four different classes: Rock, Paper, Scissors, Nothing\n",
    "\n",
    "\n",
    "Task 2: Download the model\n",
    "Download the model from the \"Tensorflow\" tab in Teachable-Machine. \n",
    "The model should be named 'keras_model.h5' and the text file containing the labels should be named 'labels.txt'.\n",
    "\n",
    "The files you are downloading contain the structure and the parameters of a deep learning model.  They are not files that can be run, and they do not contain anything readable if you look inside. Later, you will load them into your Python application in the next milestone. Make sure you push the model and labels to your GitHub repository after committing.\n",
    "\n",
    "00_Template\n",
    "01_Dev\n",
    "02_Test\n",
    "03_Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "model = load_model('keras_model.h5')\n",
    "cap = cv2.VideoCapture(0)\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "    resized_frame = cv2.resize(frame, (224, 224), interpolation = cv2.INTER_AREA)\n",
    "    image_np = np.array(resized_frame)\n",
    "    normalized_image = (image_np.astype(np.float32) / 127.0) - 1 # Normalize the image\n",
    "    data[0] = normalized_image\n",
    "    prediction = model.predict(data)\n",
    "    cv2.imshow('frame', frame)\n",
    "    # Press q to close the window\n",
    "    print(prediction)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "            \n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicore_prj_rps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 (main, Nov 24 2022, 08:09:04) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9491061224b8534fe246608a8583ba2fbb1c9cbbd7207e64d1160a42cbaf2f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
